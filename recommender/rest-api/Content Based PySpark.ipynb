{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+------+--------------------+\n",
      "|movieId|               title|              genres|imdbId|tmdbId|        genresMatrix|\n",
      "+-------+--------------------+--------------------+------+------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|114709|   862|[0, 0, 0, 1, 0, 0...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|113497|  8844|[0, 0, 0, 1, 0, 0...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|113228| 15602|[0, 1, 0, 0, 0, 0...|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|114885| 31357|[0, 1, 0, 0, 1, 0...|\n",
      "|      5|Father of the Bri...|              Comedy|113041| 11862|[0, 0, 0, 0, 0, 0...|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|113277|   949|[1, 0, 1, 0, 0, 0...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|114319| 11860|[0, 1, 0, 0, 0, 0...|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|112302| 45325|[0, 0, 0, 1, 0, 0...|\n",
      "|      9| Sudden Death (1995)|              Action|114576|  9091|[0, 0, 0, 0, 0, 0...|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|113189|   710|[0, 0, 1, 1, 0, 0...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|112346|  9087|[0, 1, 0, 0, 1, 0...|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|112896| 12110|[0, 0, 0, 0, 0, 0...|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|112453| 21032|[0, 0, 0, 1, 0, 0...|\n",
      "|     14|        Nixon (1995)|               Drama|113987| 10858|[0, 0, 0, 0, 1, 0...|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|112760|  1408|[0, 1, 0, 1, 0, 0...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|112641|   524|[1, 0, 0, 0, 1, 0...|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|114388|  4584|[0, 1, 0, 0, 1, 0...|\n",
      "|     18|   Four Rooms (1995)|              Comedy|113101|     5|[0, 0, 0, 0, 0, 0...|\n",
      "|     19|Ace Ventura: When...|              Comedy|112281|  9273|[0, 0, 0, 0, 0, 0...|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|113845| 11517|[1, 0, 1, 0, 1, 0...|\n",
      "+-------+--------------------+--------------------+------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Recommendation ALS\").getOrCreate()\n",
    "\n",
    "# do something to prove it works\n",
    "movies_df = spark.read.option(\"header\", \"true\").csv(\"data/movies.csv\", inferSchema=True)\n",
    "links_df = spark.read.option(\"header\", \"true\").csv(\"data/links.csv\", inferSchema=True).cache()\n",
    "movies_df = movies_df.join(links_df, on = ['movieId']).cache()\n",
    "ratings_df = spark.read.option(\"header\", \"true\").csv(\"data/ratings.csv\", inferSchema=True).cache()\n",
    "tags_df = spark.read.option(\"header\", \"true\").csv(\"data/tags.csv\", inferSchema=True).cache()\n",
    "\n",
    "genresList = [\"Crime\", \"Romance\", \"Thriller\", \"Adventure\", \"Drama\", \"War\", \"Documentary\", \"Fantasy\", \"Mystery\", \\\n",
    "                  \"Musical\", \"Animation\", \"Film-Noir\", \"(no genres listed)\", \"IMAX\", \"Horror\", \"Western\", \\\n",
    "                  \"Comedy\", \"Children\", \"Action\", \"Sci-Fi\"]\n",
    "\n",
    "udf_parse_genres = udf(lambda str: setGenresMatrix(str), ArrayType(IntegerType()))\n",
    "\n",
    "def setGenresMatrix(genres):\n",
    "    movieGenresMatrix = []\n",
    "    movieGenresList = genres.split('|')\n",
    "    for x in genresList:\n",
    "        if (x in movieGenresList):\n",
    "            movieGenresMatrix.append(1)\n",
    "        else:\n",
    "            movieGenresMatrix.append(0) \n",
    "    return movieGenresMatrix\n",
    "\n",
    "\n",
    "movies_df = movies_df.withColumn(\"genresMatrix\", udf_parse_genres(col(\"genres\")))\n",
    "movies_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the item feature vector\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import log10\n",
    "from pyspark.sql.functions import col\n",
    "import math\n",
    "\n",
    "tf = tags_df.groupBy([\"movieId\", \"tag\"]).count().selectExpr(\"movieId\", \"tag\",\"count AS tag_count_tf\")\n",
    "\n",
    "tags_distinct = tags_df.selectExpr(\"movieId\", \"tag\").dropDuplicates()\n",
    "df = tags_distinct.groupBy(\"tag\").count().selectExpr(\"tag\", \"count AS tag_count_df\")\n",
    "idf = math.log10(tags_df.select(\"movieId\").distinct().count())\n",
    "df = df.withColumn(\"idf\", idf - log10(\"tag_count_df\"))\n",
    "\n",
    "tf = tf.join(df, on = \"tag\", how = \"left\")\n",
    "tf = tf.withColumn(\"tf-idf\", col(\"tag_count_tf\") * col(\"idf\"))\n",
    "# show TF-IDF values for each movie\n",
    "# tf.select(\"movieId\", \"tag\", \"tf-idf\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate unit length vector of TF-IDF for normalization\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sqrt\n",
    "\n",
    "vect_len = tf.select(\"movieId\",\"tf-idf\")\n",
    "vect_len = vect_len.withColumn(\"tf-idf-sq\", col(\"tf-idf\")**2)\n",
    "vect_len = vect_len.groupby(\"movieId\").sum().withColumnRenamed(\"sum(tf-idf)\", \"tf-idf-sum\")\\\n",
    "    .withColumnRenamed(\"sum(tf-idf-sq)\", \"tf-idf-sq-sum\")\n",
    "vect_len = vect_len.withColumn(\"vect_length\", sqrt(\"tf-idf-sq-sum\"))\n",
    "tf = tf.join(vect_len,on = \"movieId\", how = \"left\")\n",
    "tf = tf.withColumn(\"tag_vec\", col(\"tf-idf\")/col(\"vect_length\"))\n",
    "\n",
    "# display the feature unit length vector of each movie: 'tag_vec'\n",
    "# tf.filter(tf[\"movieId\"] == 60756).select(\"movieId\",\"tag\",\"tf-idf\",\"vect_length\", \"tag_vec\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s implement the same and calculate user profile for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+----+\n",
      "|         tag|          tag_pref|user|\n",
      "+------------+------------------+----+\n",
      "|Boxing story|0.5954367951274172|  65|\n",
      "+------------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "ratings_filter = ratings_df.filter(ratings_df[\"rating\"] > 3)\n",
    "\n",
    "#enter user ID for analysis\n",
    "userId = 65\n",
    "user_data= ratings_filter.filter(ratings_filter[\"userId\"] == userId)\n",
    "user_data = tf.join(user_data, on = \"movieId\", how = \"inner\")\n",
    "\n",
    "user_tag_pref = user_data.groupby(\"tag\").sum().withColumnRenamed(\"sum(tag_vec)\", \"tag_pref\")\\\n",
    "    .select(\"tag\",\"tag_pref\")\n",
    "user_tag_pref = user_tag_pref.withColumn(\"user\", lit(userId))\n",
    "user_tag_pref.filter(user_tag_pref[\"tag\"] == \"Boxing story\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Compute the cosine similarities and predict item ratings\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3579\n",
      "+---+-------+------------+------------+---+------+------------+----------+-------------+-----------+-------+--------+----+\n",
      "|tag|movieId|tag_count_tf|tag_count_df|idf|tf-idf|sum(movieId)|tf-idf-sum|tf-idf-sq-sum|vect_length|tag_vec|tag_pref|user|\n",
      "+---+-------+------------+------------+---+------+------------+----------+-------------+-----------+-------+--------+----+\n",
      "+---+-------+------------+------------+---+------+------------+----------+-------------+-----------+-------+--------+----+\n",
      "\n",
      "+------------+\n",
      "|sum(tag_vec)|\n",
      "+------------+\n",
      "|        null|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "import math\n",
    "\n",
    "movieId = 123\n",
    "\n",
    "tf_movies = tf.filter(tf[\"movieId\"] == movieId)\n",
    "print(tf.count())\n",
    "\n",
    "tag_merge = tf_movies.join(user_tag_pref, on = \"tag\", how = \"left\")\n",
    "tag_merge.fillna({\"tag_pref\": 0})\n",
    "tag_merge.withColumn(\"tag_value\", col(\"tag_vec\") * col(\"tag_pref\"))\n",
    "\n",
    "\n",
    "tag_merge.show()\n",
    "tag_merge.agg(F.sum(\"tag_vec\")).show()\n",
    "\n",
    "# tag_vec_val = math.sqrt(tag_merge.agg(F.sum(\"tag_vec\")))\n",
    "# print(\"Movie id {} tag_vec {}\".format(movieId[0], tag_vec_val))\n",
    "                       \n",
    "# tag_vec_val = np.sqrt(np.sum(np.square(tag_merge['tag_vec']), axis=0))\n",
    "# tag_pref_val = np.sqrt(np.sum(np.square(user_tag_pref_all['tag_pref']), axis=0))\n",
    "        \n",
    "# tag_merge_final = tag_merge.groupby(['user','movieId'])[['tag_value']]\\\n",
    "#                                    .sum()\\\n",
    "#                                    .rename(columns = {'tag_value': 'rating'})\\\n",
    "#                                    .reset_index()\n",
    "        \n",
    "# tag_merge_final['rating']=tag_merge_final['rating']/(tag_vec_val*tag_pref_val)\n",
    "        \n",
    "# tag_merge_all = tag_merge_all.append(tag_merge_final, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "--------------\n",
    "\n",
    "* [Content Based Recommender System in Python](https://medium.com/@tomar.ankur287/content-based-recommender-system-in-python-2e8e94b16b9e)\n",
    "\n",
    "* [Data Science Series: Content-based Recommender System using Azure Databricks](https://visualbi.com/blogs/business-intelligence/data-science/data-science-series-content-based-recommender-system-using-azure-databricks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

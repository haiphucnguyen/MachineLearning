{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Recommendation ALS\").getOrCreate()\n",
    "\n",
    "# do something to prove it works\n",
    "movies_df = spark.read.option(\"header\", \"true\").csv(\"data/movies.csv\", inferSchema=True)\n",
    "links_df = spark.read.option(\"header\", \"true\").csv(\"data/links.csv\", inferSchema=True).cache()\n",
    "movies_df = movies_df.join(links_df, on = ['movieId']).cache()\n",
    "ratings_df = spark.read.option(\"header\", \"true\").csv(\"data/ratings.csv\", inferSchema=True).cache()\n",
    "tags_df = spark.read.option(\"header\", \"true\").csv(\"data/tags.csv\", inferSchema=True).cache()\n",
    "\n",
    "# movies_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the item feature vector\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import log10\n",
    "from pyspark.sql.functions import col\n",
    "import math\n",
    "\n",
    "tf = tags_df.groupBy([\"movieId\", \"tag\"]).count().selectExpr(\"movieId\", \"tag\",\"count AS tag_count_tf\")\n",
    "\n",
    "tags_distinct = tags_df.selectExpr(\"movieId\", \"tag\").dropDuplicates()\n",
    "df = tags_distinct.groupBy(\"tag\").count().selectExpr(\"tag\", \"count AS tag_count_df\")\n",
    "idf = math.log10(tags_df.select(\"movieId\").distinct().count())\n",
    "df = df.withColumn(\"idf\", idf - log10(\"tag_count_df\"))\n",
    "\n",
    "tf = tf.join(df, on = \"tag\", how = \"left\")\n",
    "tf = tf.withColumn(\"tf-idf\", col(\"tag_count_tf\") * col(\"idf\"))\n",
    "# show TF-IDF values for each movie\n",
    "# tf.select(\"movieId\", \"tag\", \"tf-idf\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate unit length vector of TF-IDF for normalization\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sqrt\n",
    "\n",
    "vect_len = tf.select(\"movieId\",\"tf-idf\")\n",
    "vect_len = vect_len.withColumn(\"tf-idf-sq\", col(\"tf-idf\")**2)\n",
    "vect_len = vect_len.groupby(\"movieId\").sum().withColumnRenamed(\"sum(tf-idf)\", \"tf-idf-sum\")\\\n",
    "    .withColumnRenamed(\"sum(tf-idf-sq)\", \"tf-idf-sq-sum\")\n",
    "vect_len = vect_len.withColumn(\"vect_length\", sqrt(\"tf-idf-sq-sum\"))\n",
    "tf = tf.join(vect_len,on = \"movieId\", how = \"left\")\n",
    "tf = tf.withColumn(\"tag_vec\", col(\"tf-idf\")/col(\"vect_length\"))\n",
    "\n",
    "# display the feature unit length vector of each movie: 'tag_vec'\n",
    "# tf.filter(tf[\"movieId\"] == 60756).select(\"movieId\",\"tag\",\"tf-idf\",\"vect_length\", \"tag_vec\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s implement the same and calculate user profile for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+----+\n",
      "|         tag|          tag_pref|user|\n",
      "+------------+------------------+----+\n",
      "|Boxing story|0.5954367951274172|  65|\n",
      "+------------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "ratings_filter = ratings_df.filter(ratings_df[\"rating\"] > 3)\n",
    "distinct_users = ratings_df.select(\"userId\").distinct()\n",
    "\n",
    "#enter user ID for analysis\n",
    "userId = 65\n",
    "user_data= ratings_filter.filter(ratings_filter[\"userId\"] == userId)\n",
    "user_data = tf.join(user_data, on = \"movieId\", how = \"inner\")\n",
    "\n",
    "user_tag_pref = user_data.groupby(\"tag\").sum().withColumnRenamed(\"sum(tag_vec)\", \"tag_pref\")\\\n",
    "    .select(\"tag\",\"tag_pref\")\n",
    "user_tag_pref = user_tag_pref.withColumn(\"user\", lit(userId))\n",
    "user_tag_pref.filter(user_tag_pref[\"tag\"] == \"Boxing story\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Compute the cosine similarities and predict item ratings\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572\n",
      "+------------+\n",
      "|sum(tag_vec)|\n",
      "+------------+\n",
      "|        null|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "import math\n",
    "\n",
    "distinct_movies = tf.select(\"movieId\").distinct().cache()\n",
    "print(distinct_movies.count())\n",
    "\n",
    "movieId = 123\n",
    "\n",
    "tf_movies = tf.filter(tf[\"movieId\"] == movieId)\n",
    "\n",
    "tag_merge = tf_movies.join(user_tag_pref, on = \"tag\", how = \"left\")\n",
    "tag_merge.fillna({\"tag_pref\": 0})\n",
    "tag_merge.withColumn(\"tag_value\", col(\"tag_vec\") * col(\"tag_pref\"))\n",
    "\n",
    "tag_merge.agg(F.sum(\"tag_vec\")).show()\n",
    "\n",
    "# tag_vec_val = math.sqrt(tag_merge.agg(F.sum(\"tag_vec\")))\n",
    "# print(\"Movie id {} tag_vec {}\".format(movieId[0], tag_vec_val))\n",
    "                       \n",
    "# tag_vec_val = np.sqrt(np.sum(np.square(tag_merge['tag_vec']), axis=0))\n",
    "# tag_pref_val = np.sqrt(np.sum(np.square(user_tag_pref_all['tag_pref']), axis=0))\n",
    "        \n",
    "# tag_merge_final = tag_merge.groupby(['user','movieId'])[['tag_value']]\\\n",
    "#                                    .sum()\\\n",
    "#                                    .rename(columns = {'tag_value': 'rating'})\\\n",
    "#                                    .reset_index()\n",
    "        \n",
    "# tag_merge_final['rating']=tag_merge_final['rating']/(tag_vec_val*tag_pref_val)\n",
    "        \n",
    "# tag_merge_all = tag_merge_all.append(tag_merge_final, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "--------------\n",
    "\n",
    "* [Content Based Recommender System in Python](https://medium.com/@tomar.ankur287/content-based-recommender-system-in-python-2e8e94b16b9e)\n",
    "\n",
    "* [Data Science Series: Content-based Recommender System using Azure Databricks](https://visualbi.com/blogs/business-intelligence/data-science/data-science-series-content-based-recommender-system-using-azure-databricks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
